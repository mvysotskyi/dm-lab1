{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3 Decision tree algorithm\n",
    "Another approach to decision tree learning is the ID3 algorithm. ID3 is a top-down, greedy algorithm that builds a decision tree by choosing the attribute that best classifies the training examples at each step. The ID3 algorithm is a special case of the more general C4.5 algorithm, which is a modification of ID3 that can handle continuous attributes. The ID3 algorithm is described in detail in Quinlan (1986). The ID3 algorithm is summarized below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset\n",
    "As ID3 algorithm can only handle categorical data, we will use the approbriate dataset [play_tennis.csv](play_tennis.csv) for this algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('play_tennis.csv', index_col=0)\n",
    "y = dataset['play']\n",
    "X = dataset.drop('play', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'Yes', 'Yes', 'Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Sunny', 'Hot', 'High', 'Weak'],\n",
       "       ['Sunny', 'Hot', 'High', 'Strong'],\n",
       "       ['Overcast', 'Hot', 'High', 'Weak'],\n",
       "       ['Rain', 'Mild', 'High', 'Weak'],\n",
       "       ['Rain', 'Cool', 'Normal', 'Weak'],\n",
       "       ['Rain', 'Cool', 'Normal', 'Strong'],\n",
       "       ['Overcast', 'Cool', 'Normal', 'Strong'],\n",
       "       ['Sunny', 'Mild', 'High', 'Weak'],\n",
       "       ['Sunny', 'Cool', 'Normal', 'Weak'],\n",
       "       ['Rain', 'Mild', 'Normal', 'Weak'],\n",
       "       ['Sunny', 'Mild', 'Normal', 'Strong'],\n",
       "       ['Overcast', 'Mild', 'High', 'Strong'],\n",
       "       ['Overcast', 'Hot', 'Normal', 'Weak'],\n",
       "       ['Rain', 'Mild', 'High', 'Strong']], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.to_numpy()\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3 Algorithm code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create node class for using in ID3 algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, decision: int = None, attribute: int = None) -> None:\n",
    "        \"\"\"\n",
    "        Create a node in the decision tree.\n",
    "        \"\"\"\n",
    "        self.decision = decision\n",
    "        self.attribute = attribute\n",
    "        self.children = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is the main class of ID3 algorithm.\n",
    "He uses this hyperparameters:\n",
    "* *max_depth*: maximum depth of the tree\n",
    "* *min_samples_split*: minimum number of samples required to split an internal node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3DecisionTree:\n",
    "    def __init__(self, max_depth: int = 3, min_samples_split: int = 0):\n",
    "        \"\"\"\n",
    "        Initialize the decision tree.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_depth : int\n",
    "            The maximum depth of the tree.\n",
    "        min_samples_split : int\n",
    "            The minimum number of samples required to split an internal node.\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def _entropy(self, y: np.array) -> float:\n",
    "        \"\"\"\n",
    "        Returns the entropy of a given set of labels.\n",
    "        \"\"\"\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        p = counts / len(y)\n",
    "        return -np.sum(p * np.log2(p))\n",
    "    \n",
    "    def _information_gain(self, X: np.array, y: np.array, attribute: int) -> float:\n",
    "        \"\"\"\n",
    "        Returns the information gain of a given attribute.\n",
    "        \"\"\"\n",
    "        unique, counts = np.unique(X[:, attribute], return_counts=True)\n",
    "        p = counts / len(X)\n",
    "        entropy = np.sum(p * self._entropy(y[X[:, attribute] == unique[0]]))\n",
    "        return self._entropy(y) - entropy\n",
    "    \n",
    "    def _best_attribute(self, X: np.array, y: np.array, attributes: np.array) -> tuple:\n",
    "        \"\"\"\n",
    "        Returns the best attribute to split on and its index in the attributes array.\n",
    "        \"\"\"\n",
    "        a = [self._information_gain(X, y, attribute) for attribute in attributes]\n",
    "        return (np.argmax(a), attributes[np.argmax(a)])\n",
    "    \n",
    "    def _major_class(self, y: np.array) -> int:\n",
    "        \"\"\"\n",
    "        Returns the most common class in a given set of labels.\n",
    "        \"\"\"\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        return unique[np.argmax(counts)]\n",
    "\n",
    "    def fit(self, X, y) -> None:\n",
    "        \"\"\"\n",
    "        Build decision tree classifier.\n",
    "        \"\"\"\n",
    "        features = np.arange(X.shape[1])\n",
    "        self.tree = self._build_tree(X, y, features)\n",
    "\n",
    "    def _build_tree(self, X: np.array, y: np.array, features: np.array, depth: int = 0) -> Node:\n",
    "        \"\"\"\n",
    "        Recursively build the decision tree.\n",
    "        \"\"\"\n",
    "        if np.unique(y).size == 1:\n",
    "            return Node(y[0])\n",
    "        \n",
    "        if features.size == 0:\n",
    "            return Node(self._major_class(y))\n",
    "        \n",
    "        if depth >= self.max_depth or X.size < self.min_samples_split:\n",
    "            return Node(self._major_class(y))\n",
    "        \n",
    "        best_attr = self._best_attribute(X, y, features)\n",
    "        node = Node(None, best_attr[1])\n",
    "\n",
    "        for value in np.unique(X[:, best_attr]):\n",
    "            subset_X = X[X[:, best_attr[1]] == value]\n",
    "            subset_y = y[X[:, best_attr[1]] == value]\n",
    "\n",
    "            if subset_X.size > 0:\n",
    "                node.children[value] = self._build_tree(subset_X, subset_y, np.delete(features, best_attr[0]), depth=depth+1)\n",
    "            else:\n",
    "                node.children[value] = Node(self._major_class(y))\n",
    "\n",
    "        return node\n",
    "    \n",
    "    def _predict(self, x: np.array, node: Node) -> int:\n",
    "        \"\"\"\n",
    "        Recursively predict the class of a given sample.\n",
    "        \"\"\"\n",
    "        if node.decision is not None:\n",
    "            return node.decision\n",
    "        else:\n",
    "            return self._predict(x, node.children[x[node.attribute]])\n",
    "\n",
    "    def predict(self, X: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Predict classes for X samples.\n",
    "        \"\"\"\n",
    "        return np.array([self._predict(x, self.tree) for x in X])\n",
    "    \n",
    "    def evaluate(self, X: np.array, y: np.array) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the accuracy of the decision tree.\n",
    "        \"\"\"\n",
    "        return np.sum(self.predict(X) == y) / len(y)\n",
    "    \n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test ID3 algorithm.\n",
    "We create a tree with maximum depth of 3 and minimum number of samples required to split an internal node is 2.\n",
    "Interface of the tree is similar to sklearn decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ID3DecisionTree(max_depth=3, min_samples_split=2)\n",
    "clf.fit(X, y)\n",
    "clf.evaluate(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the accuracy of the tree is 1.0, which means that the tree perfectly classifies the training set. Of course, the tree is overfitting the training set. So, let's try to split out dataset into train and test sets and check the accuracy of the tree on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = ID3DecisionTree(max_depth=3, min_samples_split=2)\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "clf2.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ff939caeccb051389d020a120ffe65b019ca0fb7476a0af005fed9891f80fae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
