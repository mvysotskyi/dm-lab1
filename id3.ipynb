{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('play_tennis.csv', index_col=0)\n",
    "y = dataset['play']\n",
    "X = dataset.drop('play', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'Yes', 'Yes', 'Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Sunny', 'Hot', 'High', 'Weak'],\n",
       "       ['Sunny', 'Hot', 'High', 'Strong'],\n",
       "       ['Overcast', 'Hot', 'High', 'Weak'],\n",
       "       ['Rain', 'Mild', 'High', 'Weak'],\n",
       "       ['Rain', 'Cool', 'Normal', 'Weak'],\n",
       "       ['Rain', 'Cool', 'Normal', 'Strong'],\n",
       "       ['Overcast', 'Cool', 'Normal', 'Strong'],\n",
       "       ['Sunny', 'Mild', 'High', 'Weak'],\n",
       "       ['Sunny', 'Cool', 'Normal', 'Weak'],\n",
       "       ['Rain', 'Mild', 'Normal', 'Weak'],\n",
       "       ['Sunny', 'Mild', 'Normal', 'Strong'],\n",
       "       ['Overcast', 'Mild', 'High', 'Strong'],\n",
       "       ['Overcast', 'Hot', 'Normal', 'Weak'],\n",
       "       ['Rain', 'Mild', 'High', 'Strong']], dtype=object)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, decision=None, attribute=None):\n",
    "        \"\"\"\n",
    "        Create a node in the decision tree.\n",
    "        \"\"\"\n",
    "        self.decision = decision\n",
    "        self.attribute = attribute\n",
    "        self.children = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3DecisionTree:\n",
    "    def __init__(self, max_depth=3, min_samples_split=0):\n",
    "        \"\"\"\n",
    "        Initialize the decision tree.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_depth : int\n",
    "            The maximum depth of the tree.\n",
    "        min_samples_split : int\n",
    "            The minimum number of samples required to split an internal node.\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        \"\"\"\n",
    "        Returns the entropy of a given set of labels.\n",
    "        \"\"\"\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        p = counts / len(y)\n",
    "        return -np.sum(p * np.log2(p))\n",
    "    \n",
    "    def _information_gain(self, X, y, attribute):\n",
    "        \"\"\"\n",
    "        Returns the information gain of a given attribute.\n",
    "        \"\"\"\n",
    "        unique, counts = np.unique(X[:, attribute], return_counts=True)\n",
    "        p = counts / len(X)\n",
    "        entropy = np.sum(p * self._entropy(y[X[:, attribute] == unique[0]]))\n",
    "        return self._entropy(y) - entropy\n",
    "    \n",
    "    def _best_attribute(self, X, y, attributes):\n",
    "        \"\"\"\n",
    "        Returns the best attribute to split on and its index in the attributes array.\n",
    "        \"\"\"\n",
    "        a = [self._information_gain(X, y, attribute) for attribute in attributes]\n",
    "        return (np.argmax(a), attributes[np.argmax(a)])\n",
    "    \n",
    "    def _major_class(self, y):\n",
    "        \"\"\"\n",
    "        Returns the most common class in a given set of labels.\n",
    "        \"\"\"\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        return unique[np.argmax(counts)]\n",
    "\n",
    "    def fit(self, X, y, features):\n",
    "        \"\"\"\n",
    "        Build decision tree classifier.\n",
    "        \"\"\"\n",
    "        self.tree = self._build_tree(X, y, features)\n",
    "\n",
    "    def _build_tree(self, X, y, features, depth=0):\n",
    "        \"\"\"\n",
    "        Recursively build the decision tree.\n",
    "        \"\"\"\n",
    "        if np.unique(y).size == 1:\n",
    "            return Node(y[0])\n",
    "        \n",
    "        if features.size == 0:\n",
    "            return Node(self._major_class(y))\n",
    "        \n",
    "        if depth >= self.max_depth or X.size < self.min_samples_split:\n",
    "            return Node(self._major_class(y))\n",
    "        \n",
    "        best_attr = self._best_attribute(X, y, features)\n",
    "        node = Node(None, best_attr[1])\n",
    "\n",
    "        for value in np.unique(X[:, best_attr]):\n",
    "            subset_X = X[X[:, best_attr[1]] == value]\n",
    "            subset_y = y[X[:, best_attr[1]] == value]\n",
    "\n",
    "            if subset_X.size > 0:\n",
    "                node.children[value] = self._build_tree(subset_X, subset_y, np.delete(features, best_attr[0]), depth=depth+1)\n",
    "            else:\n",
    "                node.children[value] = Node(self._major_class(y))\n",
    "\n",
    "        return node\n",
    "    \n",
    "    def _predict(self, x, node):\n",
    "        \"\"\"\n",
    "        Recursively predict the class of a given sample.\n",
    "        \"\"\"\n",
    "        if node.decision is not None:\n",
    "            return node.decision\n",
    "        else:\n",
    "            return self._predict(x, node.children[x[node.attribute]])\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict classes for X samples.\n",
    "        \"\"\"\n",
    "        return np.array([self._predict(x, self.tree) for x in X])\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"\n",
    "        Evaluate the accuracy of the decision tree.\n",
    "        \"\"\"\n",
    "        return np.sum(self.predict(X) == y) / len(y)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ID3DecisionTree(max_depth=9)\n",
    "clf.fit(X, y, np.arange(X.shape[1]))\n",
    "clf.evaluate(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ff939caeccb051389d020a120ffe65b019ca0fb7476a0af005fed9891f80fae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
